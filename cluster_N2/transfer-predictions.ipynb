{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0979db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.metrics import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb0cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairing \n",
    "input_file = 'Data-files/transfer/heteronuclear-57-15features-degree2.xlsx'\n",
    "reference_file = 'Data-files/transfer/homonuclear-159-15features-degree2.xlsx'\n",
    "\n",
    "data = pd.read_excel(input_file)\n",
    "reference_data = pd.read_excel(reference_file)\n",
    "sample_ids = data['Clusters']  \n",
    "targets = data['lg(k1)']  \n",
    "features = data.iloc[:, 2:]  \n",
    "\n",
    "reference_samples = reference_data[['ID', 'Clusters', 'lg(k1)'] + list(reference_data.columns[3:])]\n",
    "\n",
    "def calculate_differences(reference_sample_id):\n",
    "    pairwise_samples = []\n",
    "    pairwise_targets = []\n",
    "    pairwise_ids = []\n",
    "\n",
    "    reference_sample = reference_samples[reference_samples['ID'] == reference_sample_id]  \n",
    "    reference_features = reference_sample.iloc[:, 3:].values.flatten()  \n",
    "    reference_target = reference_sample['lg(k1)'].values[0]  \n",
    "\n",
    "    for idx in range(len(data)):\n",
    "        sample_id = sample_ids[idx]\n",
    "        feature_diff = features.iloc[idx].values - reference_features  \n",
    "        target_diff = targets.iloc[idx] - reference_target  \n",
    "\n",
    "        pairwise_samples.append(feature_diff)\n",
    "        pairwise_targets.append(target_diff)\n",
    "        pairwise_ids.append(f\"{sample_id} vs {reference_sample_id}\")\n",
    "\n",
    "    pairwise_features_df = pd.DataFrame(pairwise_samples, columns=features.columns).reset_index(drop=True)\n",
    "    pairwise_targets_df = pd.DataFrame(pairwise_targets, columns=['Target Difference']).reset_index(drop=True)\n",
    "    pairwise_ids_df = pd.DataFrame(pairwise_ids, columns=['Sample Pair']).reset_index(drop=True)\n",
    "    result_df = pd.concat([pairwise_ids_df, pairwise_targets_df, pairwise_features_df], axis=1)\n",
    "    return result_df\n",
    "\n",
    "for reference_sample_id in reference_samples['ID']:\n",
    "    result_df = calculate_differences(reference_sample_id)\n",
    "    output_file = f\"Data-files/transfer/hetero-homo-{reference_sample_id}.xlsx\"\n",
    "    result_df.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2082b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "file_paths = glob.glob(\"Data-files/transfer/hetero-homo-*.xlsx\")\n",
    "loaded_model = load_model('trained-DNN/trained_model.keras', custom_objects={'mse': MeanSquaredError()})\n",
    "scaler = joblib.load('trained-DNN/scaler_model.pkl')\n",
    "reference_data = pd.read_excel('Data-files/transfer/homonuclear-159-15features-degree2.xlsx')\n",
    "baseline_values = dict(zip(reference_data['ID'], reference_data.iloc[:, 2]))\n",
    "\n",
    "all_predictions = {sample: [] for sample in range(1, 58)} \n",
    "all_sample_names = []\n",
    "\n",
    "for expt_id in range(1, 160):\n",
    "    file_path = f\"Data-files/transfer/hetero-homo-{expt_id}.xlsx\"\n",
    "    \n",
    "    if expt_id in baseline_values:\n",
    "        baseline_value = baseline_values[expt_id]\n",
    "    else:\n",
    "        print(f\"Warning: No baseline value found for {expt_id}. Skipping this file.\")\n",
    "        continue\n",
    "\n",
    "    new_data = pd.read_excel(file_path)\n",
    "    features = new_data.iloc[:, 2:] \n",
    "    real_values = new_data.iloc[:, 1].values  \n",
    "    features_scaled = scaler.transform(features)  \n",
    "    \n",
    "    predictions = loaded_model.predict(features_scaled)\n",
    "    predictions_adjusted = predictions + baseline_value\n",
    "    real_values_adjusted = real_values + baseline_value\n",
    "\n",
    "    for i, sample_id in enumerate(new_data['Sample Pair'].apply(lambda x: x.split(' vs ')[0])):\n",
    "        all_predictions[i + 1].append(predictions_adjusted[i].item()) \n",
    "        if sample_id not in all_sample_names:\n",
    "            all_sample_names.append(sample_id)  \n",
    "\n",
    "predictions_df = pd.DataFrame(all_predictions)  \n",
    "predictions_df.columns = all_sample_names  \n",
    "predictions_df = predictions_df.T  \n",
    "output_file = 'Data-files/transfer/hetero-pred.xlsx'\n",
    "predictions_df.to_excel(output_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accba10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction error\n",
    "pred_file = 'Data-files/transfer/hetero-pred.xlsx' \n",
    "pred_data = pd.read_excel(pred_file, index_col=0)  \n",
    "\n",
    "transfer_file = 'Data-files/transfer/heteronuclear-57-15features-degree2.xlsx' \n",
    "transfer_data = pd.read_excel(transfer_file)\n",
    "\n",
    "error_data = []\n",
    "sample_names = pred_data.index.tolist()\n",
    "\n",
    "for sample_name in sample_names:\n",
    "    target_value_row = transfer_data[transfer_data.iloc[:, 0] == sample_name]\n",
    "    \n",
    "    if not target_value_row.empty:\n",
    "        target_value = target_value_row.iloc[0, 1] \n",
    "        target_value_up =  target_value + 0.477121255\n",
    "        target_value_down =  target_value -0.477121255\n",
    "        prediction_values = pred_data.loc[sample_name].values\n",
    "        mean_val = np.mean(prediction_values)\n",
    "        std_dev = np.std(prediction_values)\n",
    "        #error\n",
    "        error_pred = mean_val - target_value\n",
    "        error_up = mean_val - target_value_up\n",
    "        error_down = mean_val - target_value_down\n",
    "        error_min = np.min([np.abs(error_pred), np.abs(error_up), np.abs(error_down)])\n",
    "\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.hist(prediction_values, bins=30, alpha=0.7, color='blue', label='Predicted Value')\n",
    "        plt.axvline(mean_val, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {mean_val:.4f}')\n",
    "        plt.axvline(target_value, color='green', linestyle='dashed', linewidth=1, label=f'Target Value: {target_value:.4f}')\n",
    "        plt.axvline(mean_val + std_dev, color='orange', linestyle='dashed', linewidth=1, label=f'Mean + 1 Std Dev: {mean_val + std_dev:.4f}')\n",
    "        plt.axvline(mean_val - std_dev, color='orange', linestyle='dashed', linewidth=1, label=f'Mean - 1 Std Dev: {mean_val - std_dev:.4f}')\n",
    "        plt.title(f'Prediction Distribution for {sample_name}')\n",
    "        plt.xlabel('Predicted Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        error_data.append([sample_name, mean_val, target_value, error_pred, error_up, error_down, error_min, std_dev])\n",
    "    else:\n",
    "        print(f\"Sample {sample_name} not found in transfer data.\")\n",
    "\n",
    "error_df = pd.DataFrame(error_data, columns=['Sample Name', 'Predicted Mean', 'Target Value', 'Error_pred', 'Error_up','Error_down','Error_min','Std Dev'])\n",
    "error_df.to_excel('Data-files/transfer/pred_error-all.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a4edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "data = pd.read_excel('Data-files/transfer/pred_error-all.xlsx')\n",
    "\n",
    "predicted_values = data.iloc[:, 1].values \n",
    "actual_values = data.iloc[:, 2].values     \n",
    "\n",
    "#  y = x \n",
    "x = np.linspace(min(min(predicted_values), min(actual_values)), max(max(predicted_values), max(actual_values)), 100)\n",
    "y = x\n",
    "# error bound\n",
    "upper_bound = y + 0.70\n",
    "lower_bound = y - 0.70\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(predicted_values, actual_values, color='blue', label='Predicted vs Actual', alpha=0.6)\n",
    "plt.plot(x, y, 'k--', label='y = x', linewidth=1)\n",
    "plt.plot(x, upper_bound, 'r--', label='Upper Bound (y = x + 0.1139)')\n",
    "plt.plot(x, lower_bound, 'g--', label='Lower Bound (y = x - 0.1549)')\n",
    "plt.xlim(-15,-10)\n",
    "plt.ylim(-15,-10)\n",
    "plt.xlabel('Predicted lgk1 Values')\n",
    "plt.ylabel('Actual lgk1 Values')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1c308bfca458f9df215d68744e2ecb63c676d0e0afd346427bcc8e46079976d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
